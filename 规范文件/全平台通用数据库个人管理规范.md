# 全平台通用数据库个人管理规范

||**作者**：CYP | **联系方式**：nasDSSCYP@outlook.com |
||---|---|
|| **版本**：v1.0.0 | **最后更新**：2026年2月24日 |

---

## 文档修订记录

|| 版本 | 日期 | 修订内容 | 修订人 |
||------|------|----------|--------|
|| v1.0.0 | 2026年2月24日 | 初始版本：定义数据库配置、自动删除/清理/优化与安全规范 | CYP |

---

**提示**：本规范为全平台通用基础框架，实际使用时请根据项目业务场景、数据量、数据库类型（如MySQL、PostgreSQL、MongoDB等）及性能需求灵活适配，调整配置参数、清理策略及优化规则，避免生搬硬套。

## 目录

- [一、数据库配置规范](#一数据库配置规范)
- [二、自动删除规范](#二自动删除规范)
- [三、自动清理规范](#三自动清理规范)
- [四、自动优化规范](#四自动优化规范)
- [五、安全规范](#五安全规范)
- [六、数据备份与恢复规范](#六数据备份与恢复规范)
- [七、监控与告警规范](#七监控与告警规范)
- [八、开发、测试、生产环境隔离规范](#八开发测试生产环境隔离规范)
- [九、常用工具推荐清单](#九常用工具推荐清单)
- [十、日常操作检查清单](#十日常操作检查清单)
- [十一、SQL编码规范](#十一sql编码规范)
- [十二、表设计规范](#十二表设计规范)
- [十三、多租户数据库场景规范](#十三多租户数据库场景规范)
- [十四、高可用与容灾规范](#十四高可用与容灾规范)
- [十五、云原生数据库规范](#十五云原生数据库规范)
- [十六、附则](#十六附则)

## 使用说明

### 一、适配核心原则

1. 场景适配：在不同项目中，应根据数据库类型（关系型/文档型）、读写压力、数据安全等级选择合适的配置与自动化策略，禁止直接照搬示例参数到生产环境。
2. 数据分级优先：在制定自动删除、自动清理与性能优化策略时，必须先完成数据分类分级，确保核心业务数据不会被误删或过度清理。
3. 安全与可回滚：所有自动化操作（删除、清理、结构调整）必须以“可回滚”为前提，优先保证数据安全与审计可追溯性。

### 二、落地与维护方式

1. 首次落地：在新项目接入数据库时，先根据本规范完成基础配置（字符集、连接池、日志）、备份策略与监控指标的设计，再上线业务。
2. 规则固化：将自动删除、清理、优化与备份任务固化为定时任务或运维脚本，并在仓库中维护配置文件与执行记录。
3. 文档同步：每次调整数据库关键参数（如连接数、缓存大小、自动删除周期）或安全策略时，应同步更新本规范版本与修订记录，并记录变更原因。

### 三、自查与培训

1. 自查频率：建议每月或每个大版本发布前，对照自查清单检查数据库配置、备份与安全策略是否仍满足当前业务负载。
2. 新人培训：负责数据库管理的开发者或运维在接手项目前，应通读本规范并完成一次基于测试环境的演练（备份、恢复、自动删除/清理策略验证）。
3. 工具辅助：鼓励使用免费或社区版工具（如备份脚本、监控平台、SQL 分析工具）辅助执行本规范，降低人工操作风险。

#### 规范自查清单（数据库个人管理）

为便于快速核验数据库配置、备份、安全与监控是否符合本规范，建议在附录中维护统一的《数据库个人管理自查清单》，按项目实际适配后逐项勾选确认。

# 一、数据库配置规范

## 1.1 基础配置原则

1.  统一性：同一项目下的数据库实例（含开发、测试、生产环境）采用统一的配置命名规则、编码格式及字符集，推荐字符集utf8mb4，排序规则utf8mb4_general_ci，避免乱码及兼容性问题。

2.  安全性：个人管理场景下，严格管控数据库账号权限，仅创建必要账号，分配最小权限（如查询账号仅授予SELECT权限，写入账号限制指定表的INSERT/UPDATE权限）；禁止使用默认密码、弱密码，定期更换密码，密码复杂度需包含大小写字母、数字及特殊字符，长度不低于12位。

3.  可扩展性：配置需预留一定性能冗余，根据数据增长趋势调整连接数、缓存大小等参数，避免因业务扩张导致配置瓶颈；同时适配多平台部署需求，兼容云数据库（如阿里云RDS、腾讯云CDB）与本地数据库实例的配置差异。

## 1.2 核心配置参数要求

1.  连接池配置：根据应用并发量设置最大连接数（max_connections）、最小空闲连接数（min_idle_connections），避免连接数过多导致数据库负载过高，或连接数不足导致请求阻塞。推荐默认最大连接数：开发环境50-100，生产环境100-500，可根据服务器配置（CPU、内存）微调；空闲连接超时时间（wait_timeout）设置为300-600秒，释放闲置连接。

2.  缓存配置：合理设置数据库缓存参数，如MySQL的innodb_buffer_pool_size，推荐设置为服务器物理内存的50%-70%（生产环境），提升数据读取效率；MongoDB的wiredTiger缓存大小同样适配内存比例，避免缓存不足导致磁盘IO频繁。

3.  日志配置：开启核心日志功能，包括错误日志（error log）、慢查询日志（slow query log），便于问题排查；慢查询日志阈值设置为1-2秒，记录所有超出阈值的SQL语句；日志文件按时间分割（如每日分割），避免单个日志文件过大。

4.  存储配置：数据文件与日志文件分开存储，降低IO冲突；采用分区存储策略（如按时间、业务模块分区），提升数据查询与管理效率；本地数据库需定期检查磁盘空间，预留至少20%空闲空间，云数据库设置磁盘空间告警阈值。

# 二、自动删除规范

## 2.1 自动删除适用范围

适用于临时数据、过期日志数据、冗余测试数据、有效期明确的数据（如验证码、临时令牌），核心业务数据禁止开启自动删除，需手动确认后清理。

## 2.2 自动删除策略

1.  按时间删除：针对时效性数据，设置基于时间的自动删除规则，如：

- 临时验证码、登录令牌：有效期结束后1小时内自动删除；

- 操作日志、访问日志：保留30-90天（根据项目需求调整），超出保留期自动删除；

- 测试数据：测试完成后24小时内自动删除，或按测试周期批量删除。

2.  按条件删除：针对满足特定条件的冗余数据，设置条件式自动删除，如删除状态为“已作废”且超过30天的数据、重复数据（保留最新一条）。

3.  删除执行方式：通过数据库定时任务（如MySQL的EVENT、PostgreSQL的pg_cron）或应用层定时脚本（如Python、Shell脚本）实现自动删除，优先使用数据库原生定时任务，减少跨层依赖。

## 2.3 自动删除安全控制

1.  备份前置：自动删除前必须对目标数据进行备份（推荐增量备份+定期全量备份），备份数据保留周期不低于自动删除数据的保留周期，防止误删导致数据丢失。

2.  日志记录：自动删除操作需记录详细日志，包括删除时间、删除数据量、执行脚本/任务名称、操作结果，日志保留周期不低于30天，便于追溯。

3.  灰度验证：新配置的自动删除规则，先在测试环境验证1-3天，确认删除逻辑正确、无影响核心数据后，再部署到生产环境。

# 三、自动清理规范

## 3.1 清理范围

涵盖数据库日志文件、临时文件、缓存文件、数据碎片、过期索引等，避免无用数据占用存储资源，影响数据库性能。

## 3.2 自动清理策略

1.  日志文件清理：与日志分割策略联动，清理超出保留期的日志文件（如删除90天前的慢查询日志、错误日志）；同时限制单个日志文件大小（如最大500MB），超出大小自动分割并清理历史文件。

2.  临时文件清理：数据库生成的临时文件（如查询临时表、导入导出临时文件），设置自动清理机制，每日凌晨清理当天产生的临时文件，确保临时目录无残留。

3.  缓存清理：定期清理无效缓存数据（如过期会话缓存、查询缓存），MySQL可通过设置query_cache_type和query_cache_size优化缓存，MongoDB可通过TTL索引自动清理过期缓存数据，清理周期根据缓存更新频率设置（如每小时、每日）。

4.  数据碎片清理：针对频繁更新、删除操作的表，定期整理数据碎片，优化存储结构。MySQL（InnoDB引擎）可通过OPTIMIZE TABLE语句或ALTER TABLE语句重建表整理碎片，PostgreSQL可通过VACUUM FULL语句清理碎片，清理周期推荐每周1次，避开业务高峰期。

5.  索引清理：自动检测无效索引（如从未被使用、冗余索引），定期清理，减少索引维护成本。可通过数据库性能监控工具（如MySQL的Performance Schema）分析索引使用情况，清理周期每月1次，清理前需备份索引信息，便于回滚。

## 3.3 清理执行要求

1.  执行时间：自动清理操作需安排在业务低峰期（如凌晨2:00-4:00），避免占用数据库资源，影响业务正常运行。

2.  资源控制：清理过程中限制IO占用率，避免因清理操作导致数据库响应变慢；若清理数据量较大，可分批次执行。

# 四、自动优化规范

## 4.1 优化目标

通过自动化手段优化数据库性能，提升查询效率、降低资源占用，确保数据库稳定运行，适配多平台业务场景的性能需求。

## 4.2 自动优化策略

1.  索引优化：通过数据库自带工具或第三方工具（如SQL Advisor）自动分析SQL语句，推荐缺失索引；同时检测冗余索引、无效索引，自动生成清理建议（手动确认后执行，避免误删有效索引）。对于频繁更新的表，限制索引数量，避免索引过多导致写入性能下降。

2.  SQL语句优化：开启慢查询日志后，通过工具自动分析慢查询语句，生成优化建议（如调整WHERE条件、优化JOIN关联、避免全表扫描），个人可根据建议优化SQL，或配置自动化SQL重写规则（部分数据库支持）。

3.  性能参数优化：定期监控数据库性能指标（如CPU使用率、内存占用、IO负载、连接数），设置参数自动调整规则，如当连接数达到阈值80%时，自动扩容临时连接数；当InnoDB缓存命中率低于90%（读密集型业务）或70%（混合负载）时，调整innodb_buffer_pool_size（需结合服务器资源上限，避免过度调整）。

4.  表结构优化：自动检测表结构合理性，如字段类型冗余（如用VARCHAR(255)存储长度固定的字段）、缺少主键/外键约束等，生成优化建议，个人根据业务需求调整表结构，提升数据存储效率和查询速度。

## 4.3 优化监控与反馈

1.  监控指标：实时监控数据库性能指标，包括查询响应时间、吞吐量、错误率、资源占用率等，设置告警阈值，异常时及时通知个人（如邮件、短信告警）。

2.  效果验证：自动优化操作执行后，对比优化前后的性能指标，验证优化效果；若优化导致性能下降，立即回滚配置，并排查问题原因。

# 五、安全规范

## 5.1 安全检测范围与触发条件

1.  核心检测对象：数据库入侵行为、未授权访问尝试、恶意操作（如批量篡改数据、注入攻击、删除指令注入）、异常权限变更及可疑连接行为。

2.  自动删除触发阈值（仅适用于非核心备用数据库，核心数据库禁止自动删除，仅触发隔离告警）：

- 检测到3次及以上高频未授权暴力破解，且已突破账号密码防护，疑似入侵成功；

- 识别到明确的恶意SQL注入行为，且该行为已执行并试图篡改/删除核心表数据；

- 检测到陌生IP通过异常权限登录，且发起批量删除、DROP TABLE/DATABASE等高危操作；

- 数据库被植入恶意脚本，且脚本已开始自动扩散或破坏数据完整性。

## 5.2 自动检测与删除执行流程

1.  检测工具与机制：通过数据库审计工具（如MySQL Audit、pgAudit）、入侵检测系统（IDS）或自定义监控脚本，实时监控数据库操作日志、权限变更记录及网络连接信息，实现异常行为自动识别，检测频率不低于每5分钟1次。

2.  分级响应与删除触发：

- 一级告警（疑似风险）：检测到异常但未触发高危操作，立即发送告警通知（邮件+短信），阻断可疑IP连接，保留操作日志供核查，不执行删除；

- 二级紧急响应（确认高危风险）：满足上述触发条件，系统自动执行“先备份后删除”流程——立即对目标数据库进行全量备份（备份文件存储至离线安全服务器），备份完成后1分钟内删除受影响数据库实例，同时记录完整操作链路（检测时间、风险类型、备份路径、删除执行时间）；

- 核心数据库兜底：核心数据库无论检测到何种风险，均不执行自动删除，仅触发最高级别告警，同时自动断开所有非信任连接、冻结可疑账号，保留数据库实例供人工核查处置。

3.  人工复核机制：自动删除执行后，系统需在5分钟内完成告警推送，个人需在1小时内完成风险复核，确认删除合理性；若为误判，立即通过离线备份恢复数据库实例。

## 5.3 安全防护兜底措施

### 5.3.1 权限隔离管控

数据库删除权限与日常操作权限完全分离，自动删除功能仅授予系统级专用账号，该账号仅允许安全检测系统调用，禁止个人手动使用；专用账号密码采用最高安全等级，定期更换并单独存储。

### 5.3.2 访问白名单管控

仅将个人开发机、应用服务器等信任IP加入数据库访问白名单，陌生IP默认阻断；定期核查白名单有效性，移除废弃IP，减少恶意访问攻击面。

### 5.3.3 备份冗余机制

针对可能触发自动删除的数据库，配置异地多副本实时同步备份，备份数据保留周期不低于7天；自动删除前必须完成全量备份，备份文件存储至离线安全服务器，确保误删后可快速恢复。

### 5.3.4 检测工具准确性管控

#### 5.3.4.1 基线模型建立

上线初期采集1-2周数据库正常操作行为，建立基准模型，仅对偏离基线的行为触发响应；细化核心操作专属基线，信任IP发起的合法高危操作（如授权后的DROP操作）不触发告警。

#### 5.3.4.2 规则库更新管理

每月更新检测规则库，同步已知攻击特征、CVE漏洞信息，剔除过时无效规则；新规则需在测试环境灰度验证3-7天，统计误判率、漏判率达标后再部署至生产环境。

#### 5.3.4.3 多维度交叉验证

采用"数据库审计工具+IDS入侵检测系统+自定义监控脚本"多维度交叉验证，仅当至少两个维度同时检测到高危风险时，才触发二级紧急响应；高危操作增设10分钟人工预校验节点，无人工驳回则自动执行后续流程。

#### 5.3.4.4 误判案例管理

建立误判案例库，记录误判场景、触发规则、原因分析及优化方案，每季度复盘迭代规则；工具需支持误判反馈功能，便于动态调整检测灵敏度。

### 5.3.5 检测工具稳定性管控

检测工具采用双活/集群部署模式，本地工具设置主备节点，云工具开启高可用配置，规避单点故障导致检测中断。工具运行资源与数据库实例物理隔离，单独分配CPU、内存资源，限制IO占用率不超过服务器总IO的30%，避免影响数据库核心业务。开启工具全链路运行日志，记录检测过程、规则调用、告警触发及报错信息，日志保留90天；同时监控工具在线状态、检测延迟（阈值≤3秒），工具离线5分钟内推送告警通知。选用官方长期支持（LTS）版本工具，升级前备份配置文件与规则库，制定回滚方案；配置文件通过Git进行版本控制，变更操作留存可追溯记录。

### 5.3.6 定期演练与压力测试

每月结合安全流程演练，在测试环境模拟高并发SQL、海量日志写入、新型攻击等场景，验证工具极限负载下的准确性与稳定性。每季度开展灾备演练，模拟工具故障场景，验证备用工具接管效率，确保检测服务不中断。演练过程全程记录，形成可追溯报告，根据演练结果优化检测阈值与响应逻辑。

# 六、数据备份与恢复规范

## 6.1 备份策略

### 6.1.1 备份类型与频率

| 备份类型 | 频率 | 保留周期 | 适用场景 |
|----------|------|----------|----------|
| 全量备份 | 每日1次（凌晨低峰期） | 7天 | 基础备份点，用于完整恢复 |
| 增量备份 | 每6小时1次 | 3天 | 补充全量备份，降低数据丢失风险 |
| 差异备份 | 每周1次 | 30天 | 长期归档，满足合规要求 |
| 实时同步 | 持续 | 7天 | 主从复制、异地容灾 |

### 6.1.2 备份内容要求

1.  数据库数据：包含所有业务数据表、系统表
2.  数据库结构：DDL脚本备份（存储过程、视图、触发器等）
3.  配置文件：数据库配置文件（my.cnf、postgresql.conf等）
4.  用户权限：账户信息、权限配置脚本
5.  增量日志：binlog（WAL日志）用于point-in-time恢复

## 6.2 备份存储规范

1.  **存储位置**：
   - 本地备份：存储于数据库服务器本地磁盘，采用独立分区
   - 异地备份：上传至云存储（OSS、S3）或远程服务器
   - 离线备份：定期导出至移动存储设备（按月执行）

2.  **存储安全**：
   - 备份文件加密存储（AES-256算法）
   - 独立于数据库服务器的存储权限管控
   - 备份目录禁止对外网开放访问

3.  **存储容量**：
   - 预留备份存储空间不低于数据库实际大小的2倍
   - 设置存储空间告警阈值（使用率达80%时告警）

## 6.3 恢复流程规范

### 6.3.1 恢复场景分级

| 级别 | 场景 | 恢复时间目标（RTO） | 恢复点目标（RPO） |
|------|------|---------------------|-------------------|
| P0 | 整体数据库故障 | 1小时内 | 5分钟内 |
| P1 | 单个数据库损坏 | 30分钟内 | 1小时内 |
| P2 | 单表数据误删 | 15分钟内 | 2小时内 |
| P3 | 历史数据查询 | 4小时内 | 不限 |

### 6.3.2 恢复操作流程

1.  **确认恢复需求**：明确恢复时间点、恢复范围
2.  **停止写入操作**：防止恢复过程中新数据覆盖
3.  **选择备份集**：根据RPO选择最近的可用备份
4.  **执行恢复操作**：
   - 恢复全量备份
   - 应用增量日志（若需要point-in-time恢复）
5.  **数据校验**：验证恢复数据的完整性和一致性
6.  **恢复服务**：确认无误后恢复业务访问

### 6.3.3 恢复测试规范

1.  **定期演练**：每月执行1次备份恢复演练
2.  **演练内容**：随机抽取备份集，执行完整恢复流程
3.  **演练记录**：记录恢复耗时、数据完整性验证结果
4.  **问题整改**：演练发现问题需在1周内整改完成

## 6.4 备份验证规范

1.  **备份完整性校验**：
   - 备份完成后立即验证文件完整性（MD5/SHA256校验）
   - 每日随机抽取备份文件进行恢复测试

2.  **备份有效性验证**：
   - 每周执行一次完整数据库恢复测试（测试环境）
   - 验证备份数据的可恢复性和完整性

3.  **自动监控**：
   - 备份任务执行状态实时监控
   - 备份失败立即告警（邮件+短信）
   - 连续3次备份失败自动触发人工介入

## 6.5 单机容器部署场景的数据清理规范（以 CYP-Registry 为示例）

1.  **销毁行为定义**：在“单容器 + 内置数据库”的部署模式下，**销毁服务实例**的标准动作必须包含：  
    - 停止容器（如 `docker compose stop` / `docker stop`）；  
    - 删除容器；  
    - 删除承载数据库数据的持久卷或数据目录（如 `docker compose down -v` 或手动删除 `single_pg_data` 等 volume）。  

2.  **强制删除要求**：对于个人开发环境 / 单机测试环境，若业务场景要求“销毁容器即完全清空数据”，则必须满足：  
    - 不得仅删除容器而保留数据库 volume；  
    - 必须通过 `down -v` 或显式 `docker volume rm` 等方式一并删除数据库数据卷，确保数据不可恢复；  
    - 若采用宿主机目录挂载作为数据库数据目录，需在执行销毁操作时显式删除该目录（如 `/var/lib/postgresql/data` 对应的宿主机路径）。  

3.  **备份前置与确认**：在执行“销毁即清库”的操作前，应遵循以下流程：  
    - 按 6.1 的策略完成至少一次最新备份（如全量备份或导出关键业务数据）；  
    - 在操作文档或自动化脚本中加入**二次确认**步骤（如 `--yes-i-know-this-will-delete-all-data` 标志），防止误操作；  
    - 在变更记录或运维日志中记录本次销毁操作的时间、执行人、目标实例标识（如容器名 / Compose 项目名）及备份位置。  

4.  **脚本与工具约束**：  
    - 所有用于“一键销毁单机环境”的脚本（例如 `docker-compose.single.yml` 搭配的管理脚本）必须显式声明是否会删除数据库数据卷；  
    - 若脚本意图实现“彻底清理”（包括数据库），则默认行为应为 `docker compose down -v` 或等效指令，并在帮助信息和项目文档中加粗提示；  
    - 若脚本仅停止/重启服务而不清理数据，应在命名和文档中明确区分（如 `restart` vs `destroy-with-data`），避免误用。  

5.  **适用范围说明**：本条为**单机 / 个人环境附加规范**，适用于：  
    - All-in-One 单镜像部署（容器内自带 PostgreSQL 等数据库）；  
    - 使用本地 Docker volume 或宿主机目录持久化数据库的场景。  
   对于生产环境和多节点集群，不得直接依赖“删容器 = 清库”作为数据销毁方式，而应采用标准的备份与数据擦除流程，并遵循前述备份与恢复规范。  

# 七、监控与告警规范

## 7.1 监控指标体系

### 7.1.1 基础性能指标

| 指标类别 | 具体指标 | 告警阈值 | 采集频率 |
|----------|----------|----------|----------|
| 连接指标 | 当前连接数 / 最大连接数 | >80% | 10秒 |
| 连接指标 | 连接等待时间 | >100ms | 10秒 |
| 性能指标 | QPS（每秒查询数） | 根据基线浮动>30% | 10秒 |
| 性能指标 | 平均查询响应时间 | >500ms | 10秒 |
| 性能指标 | 慢查询数量（>1秒） | >10个/分钟 | 1分钟 |
| 资源指标 | CPU使用率 | >80%持续5分钟 | 10秒 |
| 资源指标 | 内存使用率 | >85% | 10秒 |
| 资源指标 | 磁盘IO等待 | >20% | 10秒 |
| 资源指标 | 磁盘空间使用率 | >80% | 5分钟 |

### 7.1.2 数据库特有指标

| 数据库类型 | 关键指标 | 说明 |
|------------|----------|------|
| MySQL | Innodb_buffer_pool_hit_rate | 缓冲池命中率，<95%告警 |
| MySQL | Innodb_row_lock_waits | 行锁等待次数，>0持续告警 |
| MySQL | Binlog文件大小增长 | 异常增长可能预示问题 |
| PostgreSQL | WAL归档状态 | 未归档持续>1小时告警 |
| PostgreSQL | 死元组比例 | >20%需执行VACUUM |
| MongoDB | 连接池状态 | 连接池耗尽告警 |
| MongoDB | 副本集同步延迟 | >10秒告警 |

## 7.2 告警管理规范

### 7.2.1 告警级别定义

| 级别 | 名称 | 定义 | 通知方式 |
|------|------|------|----------|
| P1 | 紧急 | 数据库不可用或严重性能问题 | 电话+短信+邮件+即时通讯 |
| P2 | 重要 | 性能下降或功能受损 | 短信+邮件+即时通讯 |
| P3 | 警告 | 潜在风险指标异常 | 邮件+即时通讯 |
| P4 | 提示 | 需要关注的趋势变化 | 邮件 |

### 7.2.2 告警处理流程

1.  **告警接收**：收到告警后5分钟内确认
2.  **问题定位**：分析告警原因，定位问题根因
3.  **应急处理**：执行应急预案或回滚操作
4.  **问题修复**：根本性解决告警问题
5.  **复盘总结**：记录处理过程，优化响应流程

### 7.2.3 告警收敛机制

1.  **相同告警收敛**：5分钟内相同告警合并为1条
2.  **关联告警收敛**：相关联的告警合并推送
3.  **告警静默**：维护期间可设置临时静默规则

## 7.3 监控工具与展示

1.  **监控工具**：Prometheus + Grafana / 云数据库控制台 / ELK Stack
2.  **仪表盘要求**：
   - 实时展示核心指标
   - 支持时间范围选择
   - 支持多维度钻取分析
   - 自定义告警规则配置

3.  **数据保留**：
   - 详细监控数据保留7天
   - 聚合监控数据保留90天
   - 告警历史记录保留180天

# 八、开发、测试、生产环境隔离规范

## 8.1 环境隔离原则

1.  **网络隔离**：三套环境部署在不同网络区域，禁止跨环境访问
2.  **数据隔离**：测试环境使用脱敏数据或模拟数据
3.  **权限隔离**：不同环境使用不同账号，权限独立管理
4.  **配置隔离**：环境配置文件独立管理，禁止混用

## 8.2 环境配置标准

| 配置项 | 开发环境 | 测试环境 | 生产环境 |
|--------|----------|----------|----------|
| 数据规模 | 小规模（<1GB） | 中规模（1-50GB） | 视业务而定 |
| 连接数 | 10-50 | 50-200 | 100-500+ |
| 备份频率 | 按需 | 每日 | 每日+增量 |
| 日志级别 | DEBUG | INFO | WARN/ERROR |
| 性能监控 | 基础 | 完整 | 完整+自定义 |

## 8.3 数据脱敏规范

1.  **脱敏范围**：
   - 个人信息：姓名、手机号、身份证号、地址等
   - 敏感数据：密码、密钥、令牌等
   - 业务数据：薪资、订单金额等

2.  **脱敏方式**：
   - 手机号：138****8888
   - 身份证号：110***********1234
   - 姓名：张*三

## 8.4 环境变更流程

1.  **变更申请**：提交变更申请单，包含变更内容、影响范围
2.  **变更审批**：测试环境变更个人审批，生产环境需额外审批
3.  **变更执行**：在维护窗口期内执行变更
4.  **变更验证**：变更后验证功能正常
5.  **变更记录**：记录变更详情，纳入变更日志

# 九、常用工具推荐清单

## 9.1 数据库管理工具

| 工具名称 | 支持数据库 | 平台 | 特点 |
|----------|------------|------|------|
| DBeaver | MySQL、PostgreSQL、MongoDB等 | Windows/Mac/Linux | 开源免费，插件丰富 |
| Navicat | MySQL、PostgreSQL、Oracle等 | Windows/Mac/Linux | 界面美观，功能强大 |
| DataGrip | 多数据库 | Windows/Mac/Linux | JetBrains出品，IDE集成 |
| MySQL Workbench | MySQL | Windows/Mac/Linux | 官方工具，ER建模优秀 |
| pgAdmin | PostgreSQL | Web/Desktop | PostgreSQL官方管理工具 |

## 9.2 监控与性能工具

| 工具名称 | 用途 | 部署方式 |
|----------|------|----------|
| Prometheus | 指标采集与存储 | 容器/独立部署 |
| Grafana | 监控可视化 | 容器/独立部署 |
| PMM (Percona Monitoring and Management) | MySQL/MongoDB监控 | 容器部署 |
| pgHero | PostgreSQL性能监控 | Rails应用 |
| sql-explain | SQL执行计划分析 | Web工具 |

## 9.3 备份与恢复工具

| 工具名称 | 支持数据库 | 特点 |
|----------|------------|------|
| mysqldump | MySQL | 官方逻辑备份工具 |
| pg_dump | PostgreSQL | 官方逻辑备份工具 |
| XtraBackup | MySQL | 物理备份工具，支持热备份 |
| mongodump | MongoDB | 官方备份工具 |
| RMAN | Oracle | Oracle官方恢复管理器 |

## 9.4 SQL优化工具

| 工具名称 | 用途 | 特点 |
|----------|------|------|
| EXPLAIN | 执行计划分析 | 数据库原生支持 |
| SQL Advisor | SQL优化建议 | 自动化优化建议 |
| pt-query-digest | 慢查询分析 | Percona工具集 |
| EverSQL | SQL优化 | 在线SQL优化服务 |

# 十、日常操作检查清单

## 10.1 每日检查清单

- [ ] 数据库服务状态正常（可连接、无报错）
- [ ] 磁盘空间使用率 <80%
- [ ] 连接数使用率 <80%
- [ ] 慢查询日志无异常增长
- [ ] 备份任务执行成功
- [ ] 告警列表无未处理告警

## 10.2 每周检查清单

- [ ] 执行数据碎片整理（OPTIMIZE TABLE / VACUUM）
- [ ] 检查并清理过期索引
- [ ] 验证备份数据可恢复性
- [ ] 审查慢查询TOP 10，优化高频慢查询
- [ ] 检查用户权限合理性
- [ ] 更新安全补丁（如有发布）

## 10.3 每月检查清单

- [ ] 执行完整备份恢复演练
- [ ] 审查并归档历史日志
- [ ] 检查并清理无效账号
- [ ] 评估存储容量使用趋势
- [ ] 更新数据库配置优化建议
- [ ] 安全规则库更新
- [ ] 灾备演练（每季度）

## 10.4 检查记录模板

```
检查日期：____年____月____日
检查人员：____________

每日检查：
- 数据库服务状态：□正常 □异常（备注：____________）
- 磁盘空间：____%使用率
- 连接数：____/____（____%）
- 慢查询数量：____个
- 备份状态：□成功 □失败
- 待处理告警：____个

异常情况记录：
________________________________________________

处理措施：
________________________________________________

签字：____________
```

# 十一、SQL编码规范

## 11.1 命名规范

### 11.1.1 表命名规范

1.  **命名格式**：采用小写字母+下划线格式，如 `user_account`、`order_detail`
2.  **前缀规范**：
   - 系统表添加 `sys_` 前缀，如 `sys_config`、`sys_dictionary`
   - 日志表添加 `log_` 前缀，如 `log_operation`、`log_access`
   - 临时表添加 `tmp_` 前缀，如 `tmp_order_analysis`
   - 中间表添加 `mid_` 前缀，如 `mid_daily_statistics`
3.  **复数形式**：表名统一使用复数形式或集合名词，如 `users` 而非 `user`，`products` 而非 `product`
4.  **长度限制**：表名长度不超过30个字符

### 11.1.2 字段命名规范

1.  **通用字段**：
   - 主键统一使用 `id`（BIGINT类型）或业务唯一标识如 `order_no`
   - 创建时间：`created_at`（DATETIME类型）
   - 更新时间：`updated_at`（DATETIME类型）
   - 创建人：`created_by`（BIGINT或VARCHAR）
   - 更新人：`updated_by`（BIGINT或VARCHAR）
   - 软删除标记：`deleted_at`（DATETIME类型）或 `is_deleted`（TINYINT类型）
   - 状态字段：`status`（TINYINT或ENUM类型）
   - 备注字段：`remark`（TEXT类型）

2.  **外键命名**：统一使用 `表名_id` 格式，如 `user_id`、`role_id`

3.  **时间字段**：统一使用 `_at` 后缀，如 `order_at`、`payment_at`

4.  **类型字段**：统一使用 `_type` 后缀，如 `order_type`、`payment_type`

### 11.1.3 索引命名规范

1.  **主键索引**：`pk_表名_字段名`，如 `pk_user_id`
2.  **唯一索引**：`uk_表名_字段名`，如 `uk_user_email`
3.  **普通索引**：`idx_表名_字段名`，如 `idx_order_status`
4.  **复合索引**：`idx_表名_字段1_字段2`，如 `idx_order_user_status`

## 11.2 SQL编写规范

### 11.2.1 基本书写规范

1.  **关键字大写**：SQL关键字统一大写，如 `SELECT`、`INSERT`、`UPDATE`、`DELETE`、`WHERE` 等
2.  **缩进规范**：使用2个空格缩进，保持代码整齐
3.  **逗号规范**：列名后的逗号与列名在同一行，如 `name, age, gender`
4.  **空格规范**：运算符两侧添加空格，如 `WHERE status = 1` 而非 `WHERE status=1`
5.  **换行规范**：
   - SELECT语句超过5个字段时，每个字段单独一行
   - WHERE条件每个条件单独一行
   - JOIN语句每个连接单独一行

### 11.2.2 SELECT语句规范

1.  **禁止使用 SELECT ***：明确列出所需字段，避免查询不必要的列
2.  **分页查询**：统一使用 `LIMIT OFFSET` 语法，避免使用 `LIMIT PAGE_SIZE OFFSET`
3.  **批量查询**：IN语句中的元素数量不超过1000个
4.  **避免函数运算**：WHERE条件中避免对字段进行函数运算，如 `DATE(created_at) = '2024-01-01'` 改为 `created_at >= '2024-01-01 00:00:00' AND created_at < '2024-01-02 00:00:00'`

### 11.2.3 INSERT语句规范

1.  **明确指定字段**：INSERT语句必须指定插入的字段名，不使用 `INSERT INTO table VALUES (...)`
2.  **批量插入**：单次INSERT语句插入数据不超过1000行
3.  **IGNORE使用**：对于可能重复的数据，使用 `INSERT IGNORE` 或 `ON DUPLICATE KEY UPDATE`

### 11.2.4 UPDATE语句规范

1.  **必须带WHERE条件**：UPDATE语句必须包含WHERE条件，禁止执行全表更新
2.  **影响行数限制**：执行前确认影响行数，建议单次更新不超过10000行
3.  **禁止在WHERE中使用子查询**：可能导致死锁或性能问题

### 11.2.5 DELETE语句规范

1.  **必须带WHERE条件**：DELETE语句必须包含WHERE条件，禁止执行全表删除
2.  **软删除优先**：优先使用软删除（更新deleted_at字段），仅在必要时使用硬删除
3.  **批量删除**：分批删除大量数据，每批不超过5000行，避免长时间锁表

## 11.3 性能优化规范

### 11.3.1 查询优化

1.  **避免全表扫描**：确保每个查询都有合适的索引支撑
2.  **优化JOIN关联**：
   - 关联字段类型必须一致
   - 小表驱动大表（EXPLAIN时 rows列小的表在前）
   - 避免超过3个表的JOIN关联
3.  **使用覆盖索引**：查询字段全部在索引中时，可直接返回，避免回表
4.  **避免使用临时表**：减少使用 `UNION`、`DISTINCT`、`GROUP BY` 等产生临时表的操作

### 11.3.2 索引使用规范

1.  **遵循最左前缀原则**：复合索引字段顺序与查询条件顺序一致
2.  **控制索引数量**：单表索引数量不超过5个，单个复合索引字段不超过3个
3.  **选择性高的字段放在前面**：优先将区分度高的字段放在复合索引前面
4.  **避免冗余索引**：删除与主键索引重复的索引

### 11.3.3 EXPLAIN使用规范

1.  **执行计划分析**：重要查询上线前必须使用EXPLAIN分析执行计划
2.  **关键指标关注**：
   - `type`：至少达到 `ref` 或 `range` 级别
   - `key`：确认使用预期的索引
   - `rows`：估算扫描行数，越少越好
   - `Extra`：避免出现 `Using filesort`、`Using temporary`

## 11.4 事务与锁规范

### 11.4.1 事务规范

1.  **事务粒度**：保持事务短小精悍，执行时间控制在1秒以内
2.  **事务隔离级别**：根据业务需求选择合适的隔离级别，默认为REPEATABLE-READ
3.  **避免嵌套事务**：MySQL不支持嵌套事务，使用SAVEPOINT替代
4.  **事务日志**：记录事务开始、提交、回滚时间，便于问题排查

### 11.4.2 锁使用规范

1.  **避免死锁**：按照固定顺序访问表和行
2.  **锁等待超时**：设置合理的 `innodb_lock_wait_timeout` 参数（默认50秒）
3.  **行锁使用**：优先使用行锁，避免表锁影响并发
4.  **分布式锁**：跨服务场景使用分布式锁（如Redis实现）

# 十二、表设计规范

## 12.1 字段设计规范

### 12.1.1 数据类型选择

1.  **整数类型选择**：
   - TINYINT：状态标记（0/1）、枚举值
   - SMALLINT：数量较少的分类ID
   - INT：普通ID、计数、金额（分）
   - BIGINT：主键、大计数、高精度金额（分或厘）

2.  **字符串类型选择**：
   - CHAR：固定长度字段（如状态码、性别编码）
   - VARCHAR：可变长度字段，根据实际长度设置合理上限
   - TEXT：大文本内容（>4000字符）
   - ENUM：有限枚举值（≤20个）的状态字段

3.  **时间类型选择**：
   - DATETIME：需要精确到秒的时间（created_at、updated_at）
   - TIMESTAMP：需要自动更新的时间、时区敏感时间
   - DATE：仅需要日期（不含时间）
   - BIGINT：时间戳（毫秒级），便于计算和排序

### 12.1.2 字段属性规范

1.  **NOT NULL**：所有字段默认添加NOT NULL约束，为空值设置合理的默认值
2.  **DEFAULT值**：字段设置合理的默认值
   - 状态字段：`DEFAULT 1`（默认有效）
   - 时间字段：`DEFAULT CURRENT_TIMESTAMP`
   - 数字字段：`DEFAULT 0`
3.  **COMMENT注释**：每个字段必须添加COMMENT注释，说明字段含义
4.  **字段长度**：根据业务数据范围设置合理的长度，避免过长或过短

### 12.1.3 敏感数据处理

1.  **敏感字段加密**：
   - 密码字段存储哈希值（如bcrypt、SHA256）
   - 手机号、身份证号存储加密或脱敏值
   - 密钥、令牌字段加密存储
2.  **脱敏展示**：查询时对敏感字段进行脱敏处理

## 12.2 主键设计规范

### 12.2.1 主键类型选择

1.  **自增主键**（AUTO_INCREMENT）：
   - 优点：插入性能高、空间占用小
   - 适用场景：单表无分库分表需求
   - 缺点：存在暴露业务量、迁移困难等问题

2.  **UUID主键**：
   - 优点：全局唯一、无需查询获取
   - 缺点：插入性能低（随机UUID导致页分裂）、占用空间大（36字符）

3.  **雪花算法（Snowflake）**：
   - 优点：趋势递增、高性能、有业务含义
   - 适用场景：分布式系统、分库分表场景
   - 缺点：依赖时钟，需防止时钟回拨

### 12.2.2 主键设计建议

1.  **业务主键**：对于有业务含义的唯一标识（如订单号、用户编号），可作为业务主键
2.  **复合主键**：仅在多字段唯一性有业务意义时使用，不超过2个字段
3.  **主键自增**：大多数场景推荐使用自增主键作为聚集索引

## 12.3 索引设计规范

### 12.3.1 索引类型选择

1.  **主键索引**：自动创建聚集索引，定义主键时选择合适字段
2.  **唯一索引**：用于唯一性约束的字段
3.  **普通索引**：用于查询频率较高的字段
4.  **全文索引**：用于文本搜索场景（MyISAM、InnoDB全文索引）
5.  **空间索引**：用于地理位置数据

### 12.3.2 索引创建原则

1.  **高频查询覆盖**：WHERE、ORDER BY、GROUP BY高频出现的字段创建索引
2.  **区分度优先**：选择区分度高的字段（区分度>70%）
3.  **复合索引顺序**：
   - 区分度高的字段在前
   - 等值查询字段在前，范围查询字段在后
   - ORDER BY字段与WHERE字段顺序一致
4.  **避免过度索引**：单表索引不超过5个，每秒查询次数低的字段不建索引

### 12.3.3 索引维护规范

1.  **定期分析**：每月使用 `ANALYZE TABLE` 分析表索引使用情况
2.  **清理无效索引**：删除从未被使用的索引
3.  **监控索引大小**：避免索引占用空间过大

## 12.4 表结构变更规范

### 12.4.1 变更类型分类

1.  **在线DDL**：MySQL 5.6+支持在线DDL，变更过程不锁表
2.  **pt-online-schema-change**：Percona工具实现无锁变更
3.  **gh-ost**：GitHub开源的在线DDL工具

### 12.4.2 变更执行规范

1.  **变更评估**：
   - 评估变更对业务的影响范围
   - 预估变更耗时和锁表时间
   - 准备回滚方案
2.  **变更执行**：
   - 低峰期执行变更
   - 执行前备份表结构
   - 监控变更过程中的指标
3.  **变更验证**：
   - 验证变更后表结构正确性
   - 验证业务功能正常
   - 验证性能无明显下降

## 12.5 分表分库规范

### 12.5.1 分表策略

1.  **按时间分表**：
   - 适用场景：历史数据查询、日志数据
   - 粒度：按月、按季度、按年
   - 示例：`order_202401`、`order_202402`
2.  **按用户ID分表**：
   - 适用场景：用户相关数据
   - 分表数：2^n，便于迁移和扩展
   - 示例：`order_00`、`order_01`
3.  **按地区分表**：
   - 适用场景：地理位置相关数据
   - 示例：`order_beijing`、`order_shanghai`

### 12.5.2 分表原则

1.  **单表数据量控制**：单表数据量超过1000万行时考虑分表
2.  **分片键选择**：
   - 选择查询频率最高的字段
   - 避免数据热点
   - 均匀分布数据
3.  **预留扩展空间**：分表数预留2-3倍扩展空间

# 十三、多租户数据库场景规范

## 13.1 多租户架构模式

### 13.1.1 独立数据库模式

1.  **特点**：每个租户拥有独立的数据库实例
2.  **优点**：数据隔离性最强，安全性高
3.  **缺点**：成本高，管理复杂
4.  **适用场景**：大型客户、敏感数据、付费能力强的客户

### 13.1.2 共享数据库独立Schema模式

1.  **特点**：租户共享数据库实例，使用Schema（命名空间）隔离
2.  **优点**：成本适中，数据隔离较好
3.  **缺点**：Schema数量受限制，跨Schema查询复杂
4.  **适用场景**：中等规模租户、需一定数据隔离的场景

### 13.1.3 共享数据库共享Schema模式

1.  **特点**：所有租户共享同一数据库和Schema，通过租户ID字段隔离
2.  **优点**：成本最低，管理简单
3.  **缺点**：数据隔离性最弱，需要完善的权限控制
4.  **适用场景**：小规模租户、SaaS标准版

## 13.2 数据隔离规范

### 13.2.1 共享Schema模式的隔离措施

1.  **租户ID必传**：所有业务查询必须包含tenant_id条件
2.  **应用层隔离**：应用层强制校验租户ID，防止越权访问
3.  **数据库层隔离**：通过视图或存储过程封装数据访问
4.  **权限控制**：不同租户使用不同数据库账号

### 13.2.2 跨租户操作限制

1.  **禁止跨租户查询**：禁止在单次查询中关联不同租户数据
2.  **禁止跨租户统计**：统计数据按租户维度分别统计
3.  **审计日志**：记录所有跨租户操作

## 13.3 资源隔离规范

### 13.3.1 连接池隔离

1.  **租户级连接池**：重要租户分配独立连接池
2.  **连接数限制**：限制单个租户的最大连接数
3.  **连接超时设置**：设置合理的连接空闲超时时间

### 13.3.2 存储空间限制

1.  **配额控制**：设置每个租户的最大存储空间
2.  **容量告警**：租户存储使用率达到80%时告警
3.  **自动扩容**：支持租户存储空间动态扩容

## 13.4 租户生命周期管理

### 13.4.1 租户创建流程

1.  **资源分配**：分配数据库空间、连接池配额
2.  **初始化脚本**：执行租户初始化脚本（基础数据、默认配置）
3.  **账号创建**：创建租户专属数据库账号
4.  **验证测试**：验证租户环境正常

### 13.4.2 租户数据迁移

1.  **迁移评估**：评估迁移数据量、停机时间
2.  **迁移准备**：准备目标环境、备份源数据
3.  **迁移执行**：执行数据迁移，验证数据完整性
4.  **迁移验证**：业务验证、功能测试

### 13.4.3 租户注销流程

1.  **数据备份**：注销前备份租户数据
2.  **数据导出**：按需导出租户数据
3.  **资源回收**：回收存储空间、连接池配额、数据库账号
4.  **注销记录**：记录注销时间、原因、备份位置

# 十四、高可用与容灾规范

## 14.1 高可用架构设计

### 14.1.1 主从复制架构

1.  **一主多从**：
   - 1个主节点 + 多个从节点
   - 主节点处理写请求，从节点处理读请求
   - 适用场景：读多写少的业务
2.  **双主架构**：
   - 2个主节点互相同步
   - 任意一个主节点可处理读写请求
   - 适用场景：需要高可用写入的场景

### 14.1.2 复制模式选择

1.  **异步复制**：
   - 主节点写入后立即返回，从节点异步同步
   - 优点：写入延迟低
   - 缺点：主从切换时可能丢失少量数据
2.  **半同步复制**：
   - 主节点写入后等待至少一个从节点确认
   - 优点：数据安全性较高
   - 缺点：写入延迟增加
3.  **同步复制**：
   - 主节点写入后等待所有从节点确认
   - 优点：数据安全性最高
   - 缺点：写入延迟高，适用场景有限

### 14.1.3 故障检测与切换

1.  **健康检查**：
   - 检测间隔：每5秒检测一次
   - 检测方式：TCP连接检测、执行简单查询
   - 失败阈值：连续3次检测失败判定为故障
2.  **自动切换**：
   - 主节点故障时自动切换到从节点
   - VIP自动漂移，确保连接不中断
   - 切换时间目标：30秒内完成切换
3.  **数据一致性保障**：
   - 半同步模式下切换可保证数据不丢失
   - 异步模式切换后需补齐数据

## 14.2 容灾架构设计

### 14.2.1 同城容灾

1.  **同机房多活**：同一机房部署多个数据库节点，互为主备
2.  **跨机房主从**：同一城市不同机房部署主从节点
3.  **RPO目标**：接近0（数据实时同步）
4.  **RTO目标**：5分钟内恢复服务

### 14.2.2 异地容灾

1.  **异地灾备中心**：在异地部署完整的灾备环境
2.  **数据同步**：通过异地复制或应用层同步保持数据一致
3.  **RPO目标**：根据业务需求设定（通常1小时以内）
4.  **RTO目标**：30分钟至2小时内恢复服务

### 14.2.3 多活架构

1.  **多机房多活**：多个机房同时提供服务
2.  **数据同步**：跨机房实时数据同步
3.  **流量调度**：根据地理位置或负载调度用户流量
4.  **优点**：最高级别的高可用和容灾能力
5.  **缺点**：成本高，架构复杂

## 14.3 故障切换流程

### 14.3.1 故障识别阶段

1.  **监控告警**：监控系统检测到异常时触发告警
2.  **人工确认**：运维人员确认故障（5分钟内）
3.  **影响评估**：评估故障影响范围和业务损失

### 14.3.2 故障切换阶段

1.  **流量切换**：将业务流量切换到备用节点
2.  **DNS/VIP切换**：更新解析或漂移虚拟IP
3.  **连接重置**：断开旧连接，建立新连接
4.  **业务通知**：必要时通知相关业务方

### 14.3.3 故障恢复阶段

1.  **故障排查**：分析故障原因，修复故障节点
2.  **数据补齐**：将故障期间的数据同步到恢复的节点
3.  **切换回主**：业务平稳后切换回原主节点
4.  **复盘总结**：记录故障过程，优化应急预案

## 14.4 容灾演练规范

### 14.4.1 演练频率

1.  **常规演练**：每季度至少1次全链路容灾演练
2.  **专项演练**：重大变更后、架构调整后进行专项演练
3.  **无通知演练**：每年进行1-2次不提前通知的应急演练

### 14.4.2 演练内容

1.  **主节点故障切换**：模拟主节点故障，自动切换到从节点
2.  **从节点故障恢复**：模拟从节点故障，验证恢复流程
3.  **机房级故障切换**：模拟机房故障，切换到异地灾备
4.  **数据恢复演练**：模拟数据误删，从备份恢复数据

### 14.4.3 演练评估

1.  **演练记录**：记录演练过程、时间、数据完整性
2.  **问题整改**：发现的问题在1周内整改完成
3.  **演练报告**：输出演练报告，优化应急预案

# 十五、云原生数据库规范

## 15.1 云数据库选型规范

### 15.1.1 主流云数据库对比

| 云服务商 | 数据库服务 | 特点 | 适用场景 |
|----------|------------|------|----------|
| 阿里云 | RDS、PolarDB | 兼容MySQL/PostgreSQL，PolarDB支持计算存储分离 | 通用业务场景 |
| 腾讯云 | CDB、TDSQL | 高性能、高可用，支持分布式事务 | 游戏、电商场景 |
| AWS | RDS、Aurora | Aurora兼容MySQL/PostgreSQL，性能优异 | 国际业务、高性能场景 |
| 华为云 | RDS、GaussDB | 国产化、自主可控 | 政企、金融场景 |

### 15.1.2 选型决策因素

1.  **业务需求**：根据读写性能、数据量、事务类型选择
2.  **成本预算**：综合评估实例成本、存储成本、运维成本
3.  **技术栈兼容**：选择与现有技术栈兼容的数据库
4.  **服务等级**：根据可用性要求选择对应服务等级

## 15.2 云数据库配置规范

### 15.2.1 实例规格选择

1.  **计算规格**：根据CPU使用率（目标<70%）选择实例规格
2.  **内存规格**：根据内存使用率（目标<80%）选择
3.  **存储规格**：
   - 存储类型：SSD云盘（推荐）、高效云盘
   - IOPS：根据业务IO需求选择
   - 吞吐量：根据数据传输量选择

### 15.2.2 网络配置

1.  **VPC网络**：数据库部署在VPC内，与应用网络隔离
2.  **安全组**：配置严格的入站规则，仅允许应用服务器访问
3.  **白名单**：配置IP白名单，限制访问来源
4.  **专线连接**：跨网络访问时使用专线或VPN

### 15.2.3 备份配置

1.  **自动备份**：开启自动备份，设置备份频率和保留时间
2.  **手动备份**：重要变更前进行手动备份
3.  **跨地域备份**：开启跨地域备份，提高数据安全性
4.  **备份加密**：启用备份加密功能

## 15.3 云数据库运维规范

### 15.3.1 监控与告警

1.  **基础监控**：监控CPU、内存、磁盘、连接数等基础指标
2.  **性能监控**：监控QPS、慢查询、锁等待等性能指标
3.  **自定义告警**：根据业务需求设置告警阈值
4.  **告警通知**：配置短信、邮件、 webhook 等通知方式

### 15.3.2 参数优化

1.  **默认参数优化**：
   - `max_connections`：根据连接数需求调整
   - `wait_timeout`：设置合理的连接超时时间
   - `innodb_buffer_pool_size`：设置为可用内存的50%-70%
2.  **参数组管理**：使用参数组统一管理实例参数
3.  **参数变更**：变更前备份原参数，变更后观察效果

### 15.3.3 弹性扩展

1.  **垂直扩容**：通过变更实例规格提升性能
2.  **水平扩展**：通过读写分离、分布式架构扩展
3.  **存储扩容**：在线扩容存储空间，不影响业务
4.  **扩缩容评估**：根据监控数据评估扩缩容需求

## 15.4 云数据库安全规范

### 15.4.1 访问控制

1.  **账号管理**：
   - 创建独立应用账号，禁止使用root账号
   - 遵循最小权限原则分配权限
   - 定期审计账号权限
2.  **密码策略**：
   - 设置强密码（长度≥16位，包含大小写、数字、特殊字符）
   - 定期更换密码（建议每90天）
   - 使用密码轮换机制

### 15.4.2 数据加密

1.  **传输加密**：启用SSL/TLS加密传输
2.  **存储加密**：启用云盘加密功能
3.  **字段加密**：敏感字段应用层加密存储

### 15.4.3 安全审计

1.  **审计日志**：开启SQL审计日志，记录所有SQL操作
2.  **操作日志**：记录数据库配置变更、账号操作
3.  **日志保留**：审计日志保留180天以上

# 十六、附则

1.  本规范由个人维护，根据项目迭代、数据库版本更新及业务需求变化，定期修订（推荐每季度修订1次）。

2.  执行过程中若遇到特殊场景（如核心数据迁移、大流量峰值），可临时调整规范中的配置、策略，事后需记录调整原因及恢复时间。

3.  作者：CYP | 联系方式：nasDSSCYP@outlook.com。

> （注：文档部分内容可能由 AI 生成）